import logging
import os
import json
from typing import Dict, Any, List
from langchain_core.messages import HumanMessage, SystemMessage

from core.models import GeminiModelConfig
from core.rotator import GeminiKeyRotator
from core.sandbox_manager import get_sandbox
from core.mcp_tool_definitions import MCPToolDefinitions
from agents.crews.coding_crew.state import CodingCrewState, ProjectState

logger = logging.getLogger(__name__)

class CodingNodes:
    def __init__(self, config: GeminiModelConfig):
        self.config = config
        self.rotator = GeminiKeyRotator(config.base_url, config.api_keys)
        self.prompts = self._load_prompts()

    def _load_prompts(self) -> Dict[str, str]:
        """Loads prompt templates from the prompts directory."""
        prompts = {}
        roles = ["architect", "coder", "reviewer", "planner", "debugger", "reflection", "summarizer"]
        base_path = os.path.join(os.path.dirname(__file__), "prompts")
        
        for role in roles:
            file_path = os.path.join(base_path, f"{role}.md")
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    prompts[role] = f.read()
            except FileNotFoundError:
                logger.warning(f"Prompt file not found: {file_path}. Using fallback.")
                prompts[role] = f"You are an expert {role}."
        return prompts

    async def architect_node(self, state: CodingCrewState) -> Dict[str, Any]:
        """
        Architect analyzes the requirement and outputs a high-level plan.
        """
        logger.info("üèóÔ∏è Architect Node Running...")
        prompt_content = self.prompts["architect"]
        user_req = state.user_requirement
        
        contents = [
            {"role": "user", "parts": [{"text": f"{prompt_content}\n\nRequirement: {user_req}"}]}
        ]
        
        response_text, usage = await self.rotator.call_gemini_with_rotation(
            model_name=self.config.model_name,
            contents=contents
        )
        
        # Robust Plan Parsing
        # Assumes LLM outputs a list starting with "-" or numbered list
        plan_steps = []
        for line in response_text.split('\n'):
            line = line.strip()
            if line.startswith('- ') or (line[0].isdigit() and '. ' in line):
                # Clean up marker
                clean_step = line.split(' ', 1)[1].strip()
                plan_steps.append(clean_step)
        
        if not plan_steps:
            # Fallback if LLM was chatty
            logger.warning("Architect produced no structured plan. Using generic plan.")
            plan_steps = ["Analyze Codebase", "Implement Solution", "Verify Implementation"]

        return {
            "plan": plan_steps,
            "messages": [HumanMessage(content=response_text)]
        }

    async def coder_node(self, state: CodingCrewState) -> Dict[str, Any]:
        """
        Coder generates code for the current step using available tools.
        """
        logger.info("üë®‚Äçüíª Coder Node Running...")
        
        # Get current step
        if state.current_step_index < len(state.plan):
            current_step = state.plan[state.current_step_index]
        else:
            current_step = "Final Review and Cleanup"

        prompt_content = self.prompts["coder"]
        
        # Build Context
        history_str = ""
        if state.messages:
            # Include last few messages for context
            last_msgs = state.messages[-3:] 
            for msg in last_msgs:
                history_str += f"{msg.type}: {msg.content}\n"

        context_msg = f"""
        Current Plan Step: {current_step}
        
        Recent History:
        {history_str}
        """
        
        contents = [
            {"role": "user", "parts": [{"text": f"{prompt_content}\n\n{context_msg}"}]}
        ]
        
        # Call Gemini with Tools Definition
        response_text, usage = await self.rotator.call_gemini_with_rotation(
            model_name=self.config.model_name,
            contents=contents,
            tools=MCPToolDefinitions.get_coding_tools(),
            cached_content_name=state.project_state.cache_name 
        )
        
        return {
            "messages": [HumanMessage(content=response_text)],
            "usage_metadata": usage
        }

    async def executor_node(self, state: CodingCrewState) -> Dict[str, Any]:
        """
        Executes the tools generated by the Coder.
        Features:
        - Tool dispatching (write_file, read_file, execute_command)
        - Data Loss Prevention (DLP) for secrets
        """
        logger.info("üì¶ Executor Node Running...")
        
        last_message = state.messages[-1]
        # Parse XML tool calls
        tool_calls = MCPToolDefinitions.parse_tool_calls(last_message.content)
        
        # Retrieve the correct sandbox for this task
        sandbox = get_sandbox(state.project_state.task_id)
        if not sandbox:
            return {"execution_output": "Error: CRITICAL - Sandbox environment not found for this task."}

        results = []
        for tool in tool_calls:
            try:
                name = tool["name"]
                params = tool["parameters"]
                
                output = ""
                
                if name == "execute_command":
                    cmd = params.get("command")
                    # Use execute_shell for shell commands
                    stdout, stderr = sandbox.execute_shell(cmd)
                    output = f"Stdout: {stdout}\nStderr: {stderr}"
                    
                elif name == "write_to_file":
                    fpath = params.get("filepath")
                    content = params.get("content")
                    # Write file inside container using python helper
                    # Escaping triple quotes for safety
                    safe_content = content.replace("'''", "\\'\\'\\'")
                    code = f"""
import os
os.makedirs(os.path.dirname('{fpath}'), exist_ok=True)
with open('{fpath}', 'w', encoding='utf-8') as f:
    f.write(r'''{content}''')
print('File written successfully')
"""
                    stdout, stderr, _ = sandbox.execute_code(code)
                    output = f"Write Result: {stdout} {stderr}"

                elif name == "read_file":
                    fpath = params.get("filepath")
                    code = f"""
try:
    with open('{fpath}', 'r', encoding='utf-8') as f:
        print(f.read())
except Exception as e:
    print(f'Error reading file: {{e}}')
"""
                    stdout, stderr, _ = sandbox.execute_code(code)
                    output = stdout if stdout.strip() else stderr

                else:
                    output = f"Unknown tool: {name}"

                # [Security] Data Loss Prevention (DLP)
                # Scrub secrets before returning to LLM or Logs
                SENSITIVE_PATTERNS = ["BEGIN RSA PRIVATE KEY", "AWS_ACCESS_KEY_ID", "AIzaSy"]
                for pattern in SENSITIVE_PATTERNS:
                    if pattern in output:
                        output = output.replace(pattern, "[REDACTED_SECRET]")

                results.append(f"Tool '{name}':\n{output}")
                
            except Exception as e:
                logger.error(f"Tool execution error: {e}")
                results.append(f"Tool '{name}' Failed: {str(e)}")

        execution_summary = "\n---\n".join(results)
        
        return {
            "execution_output": execution_summary if execution_summary else "No tools executed."
        }

    async def reviewer_node(self, state: CodingCrewState) -> Dict[str, Any]:
        """
        Reviews the code changes and execution output.
        """
        logger.info("üïµÔ∏è Reviewer Node Running...")
        prompt = self.prompts["reviewer"]
        
        last_exec = state.execution_output if hasattr(state, 'execution_output') else "No execution output."
        last_plan = state.plan[state.current_step_index] if state.plan else "Unknown Step"
        
        contents = [{
            "role": "user", 
            "parts": [{"text": f"{prompt}\n\nTask Step: {last_plan}\n\nExecution Result:\n{last_exec}"}]
        }]
        
        response_text, _ = await self.rotator.call_gemini_with_rotation(
            model_name=self.config.model_name,
            contents=contents
        )
        
        # Check approval
        is_approved = "APPROVE" in response_text.upper() and "REJECT" not in response_text.upper()
        
        return {
            "messages": [HumanMessage(content=response_text)],
            "approved": is_approved
        }
